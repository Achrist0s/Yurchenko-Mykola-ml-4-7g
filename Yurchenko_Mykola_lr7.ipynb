{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Завдання 1"
      ],
      "metadata": {
        "id": "qFUAAs_gQBAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcdmLXhWQaFg",
        "outputId": "50d9f3ba-74e9-4bd3-b666-89ecc0ad1bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m122.9/154.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.13.1)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp310-cp310-linux_x86_64.whl size=2357275 sha256=91009752f83f5ed1d60bb42da2b7e1556d4a30cca45e5eb50e549ae8e074df58\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/3f/df/6acbf0a40397d9bf3ff97f582cc22fb9ce66adde75bc71fd54\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aic9zDflPjP9",
        "outputId": "902dcc84-79ff-463d-93be-a177a3259ccb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ml-100k could not be found. Do you want to download it? [Y/n] y\n",
            "Trying to download dataset from https://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
            "Done! Dataset ml-100k has been saved to /root/.surprise_data/ml-100k\n",
            "Перші 5 рядків датасету:\n",
            "('196', '242', 3.0, '881250949')\n",
            "('186', '302', 3.0, '891717742')\n",
            "('22', '377', 1.0, '878887116')\n",
            "('244', '51', 2.0, '880606923')\n",
            "('166', '346', 1.0, '886397596')\n",
            "Найкращі параметри для SVD:\n",
            "{'n_epochs': 10, 'lr_all': 0.005}\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Найкращі параметри для KNNBasic:\n",
            "{'k': 40, 'sim_options': {'name': 'msd', 'user_based': False}}\n",
            "Evaluating MAE of algorithm SVD on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "MAE (testset)     0.7570  0.7501  0.7479  0.7447  0.7467  0.7493  0.0043  \n",
            "Fit time          0.70    0.92    1.06    0.72    0.72    0.82    0.14    \n",
            "Test time         0.11    0.20    0.20    0.20    0.11    0.16    0.04    \n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating MAE of algorithm KNNBasic on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "MAE (testset)     0.7714  0.7687  0.7640  0.7793  0.7669  0.7701  0.0052  \n",
            "Fit time          0.53    0.57    0.74    0.52    0.53    0.58    0.08    \n",
            "Test time         3.57    3.89    3.79    3.59    4.65    3.90    0.39    \n",
            "Найкращий алгоритм: SVD\n",
            "Рекомендації для користувача:\n",
            "64 4.567781435339667\n",
            "178 4.550044687965974\n",
            "408 4.466954239395958\n",
            "488 4.453575491729073\n",
            "285 4.44104705176065\n",
            "50 4.434257054649086\n",
            "165 4.432111481820501\n",
            "483 4.424292318478794\n",
            "169 4.396081208396531\n",
            "134 4.3941621033661376\n"
          ]
        }
      ],
      "source": [
        "from surprise import Dataset, Reader, SVD, KNNBasic\n",
        "from surprise.model_selection import cross_validate, GridSearchCV\n",
        "from surprise.accuracy import mae\n",
        "\n",
        "# 1. Завантажте датасет для рецензій (ml-100k) за допомогою бібліотеки Surprise.\n",
        "data = Dataset.load_builtin('ml-100k')\n",
        "\n",
        "# 2. Виведіть перші 5 рядків завантаженого датасету.\n",
        "raw_ratings = data.raw_ratings[:5]\n",
        "print(\"Перші 5 рядків датасету:\")\n",
        "for line in raw_ratings:\n",
        "    print(line)\n",
        "\n",
        "# 3. Реалізуйте два алгоритми для рекомендаційної системи на основі цього датасету.\n",
        "algo1 = SVD()\n",
        "algo2 = KNNBasic()\n",
        "\n",
        "# 4. Використайте крос-валідацію для підбору оптимальних параметрів для обох алгоритмів.\n",
        "param_grid = {'n_epochs': [5, 10], 'lr_all': [0.002, 0.005]}\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
        "gs.fit(data)\n",
        "\n",
        "print(\"Найкращі параметри для SVD:\")\n",
        "print(gs.best_params['mae'])\n",
        "\n",
        "algo1 = gs.best_estimator['mae']\n",
        "\n",
        "param_grid = {'k': [20, 40], 'sim_options': {'name': ['msd', 'cosine'], 'user_based': [False]}}\n",
        "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse', 'mae'], cv=3)\n",
        "gs.fit(data)\n",
        "\n",
        "print(\"Найкращі параметри для KNNBasic:\")\n",
        "print(gs.best_params['mae'])\n",
        "\n",
        "algo2 = gs.best_estimator['mae']\n",
        "\n",
        "# 5. Оберіть найкращий алгоритм на основі середньої абсолютної помилки (MAE).\n",
        "results1 = cross_validate(algo1, data, measures=['mae'], cv=5, verbose=True)\n",
        "results2 = cross_validate(algo2, data, measures=['mae'], cv=5, verbose=True)\n",
        "\n",
        "mean_mae_algo1 = results1['test_mae'].mean()\n",
        "mean_mae_algo2 = results2['test_mae'].mean()\n",
        "\n",
        "best_algo = algo1 if mean_mae_algo1 < mean_mae_algo2 else algo2\n",
        "print(f\"Найкращий алгоритм: {'SVD' if best_algo == algo1 else 'KNNBasic'}\")\n",
        "\n",
        "# 6. Виведи рекомендації (10 фільмів) для конкретного користувача.\n",
        "trainset = data.build_full_trainset()\n",
        "best_algo.fit(trainset)\n",
        "\n",
        "user_id = str(196)  # Заміни на ID користувача, для якого потрібні рекомендації\n",
        "items = trainset.all_items()\n",
        "items = [trainset.to_raw_iid(i) for i in items]\n",
        "predictions = [best_algo.predict(user_id, iid) for iid in items]\n",
        "predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "\n",
        "print(\"Рекомендації для користувача:\")\n",
        "for pred in predictions[:10]:\n",
        "    print(pred.iid, pred.est)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Завдання 2"
      ],
      "metadata": {
        "id": "3CWLlqNaRsfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import train_test_split, cross_validate\n",
        "from surprise.accuracy import mae\n",
        "\n",
        "# 1. Завантажте датасет для рецензій (ml-100k) за допомогою бібліотеки Surprise.\n",
        "data = Dataset.load_builtin('ml-100k')\n",
        "\n",
        "# Розділіть дані на тренувальний та тестовий набори\n",
        "trainset, testset = train_test_split(data, test_size=0.25)\n",
        "\n",
        "# Створіть алгоритм SVD\n",
        "algo = SVD()\n",
        "\n",
        "# Навчіть алгоритм на тренувальному наборі\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Оцініть алгоритм на тестовому наборі\n",
        "predictions = algo.test(testset)\n",
        "print(\"MAE:\", mae(predictions))\n",
        "\n",
        "# Використайте крос-валідацію для оцінки алгоритму\n",
        "cross_validate(algo, data, measures=['MAE'], cv=5, verbose=True)\n",
        "\n",
        "# 2. Отримайте рекомендацію для певного користувача.\n",
        "trainset = data.build_full_trainset()\n",
        "algo.fit(trainset)\n",
        "\n",
        "user_id = str(196)  # Заміни на ID користувача, для якого потрібні рекомендації\n",
        "items = trainset.all_items()\n",
        "items = [trainset.to_raw_iid(i) for i in items]\n",
        "predictions = [algo.predict(user_id, iid) for iid in items]\n",
        "predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "\n",
        "print(\"Рекомендації для користувача:\")\n",
        "for pred in predictions[:10]:\n",
        "    print(pred.iid, pred.est)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Fst0cd-RvWI",
        "outputId": "ad7ab6ab-56b1-44b7-eb39-df9b3ef7da43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE:  0.7423\n",
            "MAE: 0.742339085349967\n",
            "Evaluating MAE of algorithm SVD on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "MAE (testset)     0.7410  0.7355  0.7356  0.7390  0.7346  0.7371  0.0024  \n",
            "Fit time          1.37    1.37    1.39    1.49    1.96    1.52    0.23    \n",
            "Test time         0.27    0.12    0.13    0.20    0.18    0.18    0.05    \n",
            "Рекомендації для користувача:\n",
            "318 4.624020065469233\n",
            "134 4.577526363701276\n",
            "64 4.54933003832522\n",
            "169 4.542567131960868\n",
            "408 4.5348173906993585\n",
            "474 4.490454864801153\n",
            "178 4.464608803561293\n",
            "479 4.460454887252557\n",
            "663 4.446295720072948\n",
            "515 4.412340139059769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Висновки**\n",
        "\n",
        "1. **Завантаження та підготовка даних**:\n",
        "   - Використано датасет `ml-100k` з бібліотеки `surprise`.\n",
        "   - Дані розділено на тренувальний та тестовий набори для навчання та оцінки моделі.\n",
        "\n",
        "2. **Реалізація алгоритму**:\n",
        "   - Використано алгоритм SVD для побудови рекомендаційної системи.\n",
        "   - Алгоритм навчено на тренувальному наборі даних.\n",
        "\n",
        "3. **Оцінка моделі**:\n",
        "   - Оцінка моделі проведена за допомогою метрики середньої абсолютної помилки (MAE).\n",
        "   - Використано крос-валідацію для додаткової оцінки алгоритму, що дозволило отримати більш надійні результати.\n",
        "\n",
        "4. **Отримання рекомендацій**:\n",
        "   - Після навчання моделі на повному наборі даних, отримано рекомендації для конкретного користувача.\n",
        "   - Виведено топ-10 рекомендованих фільмів для користувача з ID 196.\n",
        "\n",
        "Цей підхід дозволяє створити ефективну рекомендаційну систему, яка може надавати персоналізовані рекомендації на основі історичних даних користувачів."
      ],
      "metadata": {
        "id": "FF57HdBYSCgA"
      }
    }
  ]
}