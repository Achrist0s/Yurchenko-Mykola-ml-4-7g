{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Завдання №1"
      ],
      "metadata": {
        "id": "HMIE0xtKVEZS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSKzGBRhTLor",
        "outputId": "011ba420-6e0e-4f4a-899d-a873a9f52030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Перші кілька рядків датасету:\n",
            "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
            "0        17.99         10.38          122.80     1001.0          0.11840   \n",
            "1        20.57         17.77          132.90     1326.0          0.08474   \n",
            "2        19.69         21.25          130.00     1203.0          0.10960   \n",
            "3        11.42         20.38           77.58      386.1          0.14250   \n",
            "4        20.29         14.34          135.10     1297.0          0.10030   \n",
            "\n",
            "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
            "0           0.27760          0.3001              0.14710         0.2419   \n",
            "1           0.07864          0.0869              0.07017         0.1812   \n",
            "2           0.15990          0.1974              0.12790         0.2069   \n",
            "3           0.28390          0.2414              0.10520         0.2597   \n",
            "4           0.13280          0.1980              0.10430         0.1809   \n",
            "\n",
            "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
            "0                 0.07871  ...         25.38          17.33           184.60   \n",
            "1                 0.05667  ...         24.99          23.41           158.80   \n",
            "2                 0.05999  ...         23.57          25.53           152.50   \n",
            "3                 0.09744  ...         14.91          26.50            98.87   \n",
            "4                 0.05883  ...         22.54          16.67           152.20   \n",
            "\n",
            "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
            "0      2019.0            0.1622             0.6656           0.7119   \n",
            "1      1956.0            0.1238             0.1866           0.2416   \n",
            "2      1709.0            0.1444             0.4245           0.4504   \n",
            "3       567.7            0.2098             0.8663           0.6869   \n",
            "4      1575.0            0.1374             0.2050           0.4000   \n",
            "\n",
            "   worst concave points  worst symmetry  worst fractal dimension  \n",
            "0                0.2654          0.4601                  0.11890  \n",
            "1                0.1860          0.2750                  0.08902  \n",
            "2                0.2430          0.3613                  0.08758  \n",
            "3                0.2575          0.6638                  0.17300  \n",
            "4                0.1625          0.2364                  0.07678  \n",
            "\n",
            "[5 rows x 30 columns]\n",
            "\n",
            "Назви стовпців та типи даних:\n",
            "Index(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
            "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
            "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
            "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
            "       'smoothness error', 'compactness error', 'concavity error',\n",
            "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
            "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
            "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
            "       'worst concave points', 'worst symmetry', 'worst fractal dimension'],\n",
            "      dtype='object')\n",
            "mean radius                float64\n",
            "mean texture               float64\n",
            "mean perimeter             float64\n",
            "mean area                  float64\n",
            "mean smoothness            float64\n",
            "mean compactness           float64\n",
            "mean concavity             float64\n",
            "mean concave points        float64\n",
            "mean symmetry              float64\n",
            "mean fractal dimension     float64\n",
            "radius error               float64\n",
            "texture error              float64\n",
            "perimeter error            float64\n",
            "area error                 float64\n",
            "smoothness error           float64\n",
            "compactness error          float64\n",
            "concavity error            float64\n",
            "concave points error       float64\n",
            "symmetry error             float64\n",
            "fractal dimension error    float64\n",
            "worst radius               float64\n",
            "worst texture              float64\n",
            "worst perimeter            float64\n",
            "worst area                 float64\n",
            "worst smoothness           float64\n",
            "worst compactness          float64\n",
            "worst concavity            float64\n",
            "worst concave points       float64\n",
            "worst symmetry             float64\n",
            "worst fractal dimension    float64\n",
            "dtype: object\n",
            "\n",
            "Перевірка наявності пропущених значень:\n",
            "mean radius                0\n",
            "mean texture               0\n",
            "mean perimeter             0\n",
            "mean area                  0\n",
            "mean smoothness            0\n",
            "mean compactness           0\n",
            "mean concavity             0\n",
            "mean concave points        0\n",
            "mean symmetry              0\n",
            "mean fractal dimension     0\n",
            "radius error               0\n",
            "texture error              0\n",
            "perimeter error            0\n",
            "area error                 0\n",
            "smoothness error           0\n",
            "compactness error          0\n",
            "concavity error            0\n",
            "concave points error       0\n",
            "symmetry error             0\n",
            "fractal dimension error    0\n",
            "worst radius               0\n",
            "worst texture              0\n",
            "worst perimeter            0\n",
            "worst area                 0\n",
            "worst smoothness           0\n",
            "worst compactness          0\n",
            "worst concavity            0\n",
            "worst concave points       0\n",
            "worst symmetry             0\n",
            "worst fractal dimension    0\n",
            "dtype: int64\n",
            "\n",
            "Розмір даних:\n",
            "(569, 30)\n",
            "\n",
            "Model: Logistic Regression\n",
            "Accuracy: 0.956140350877193\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.91      0.94        43\n",
            "           1       0.95      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "Confusion Matrix:\n",
            "[[39  4]\n",
            " [ 1 70]]\n",
            "\n",
            "\n",
            "Model: Decision Tree\n",
            "Accuracy: 0.9385964912280702\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.91      0.92        43\n",
            "           1       0.94      0.96      0.95        71\n",
            "\n",
            "    accuracy                           0.94       114\n",
            "   macro avg       0.94      0.93      0.93       114\n",
            "weighted avg       0.94      0.94      0.94       114\n",
            "\n",
            "Confusion Matrix:\n",
            "[[39  4]\n",
            " [ 3 68]]\n",
            "\n",
            "\n",
            "Model: Random Forest\n",
            "Accuracy: 0.9649122807017544\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.93      0.95        43\n",
            "           1       0.96      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.96      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n",
            "Confusion Matrix:\n",
            "[[40  3]\n",
            " [ 1 70]]\n",
            "\n",
            "Best Model: Random Forest\n",
            "Results of the best model:\n",
            "[1 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
            " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
            " 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
            " 1 1 0]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# 1. Завантаження датасету та попередній аналіз даних\n",
        "# Завантаження датасету\n",
        "data = load_breast_cancer()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "\n",
        "# Перегляд перших кількох рядків\n",
        "print(\"Перші кілька рядків датасету:\")\n",
        "print(df.head())\n",
        "\n",
        "# Перевірка назв стовпців та типів даних\n",
        "print(\"\\nНазви стовпців та типи даних:\")\n",
        "print(df.columns)\n",
        "print(df.dtypes)\n",
        "\n",
        "# Перевірка наявності пропущених значень\n",
        "print(\"\\nПеревірка наявності пропущених значень:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Дослідження розміру даних\n",
        "print(\"\\nРозмір даних:\")\n",
        "print(df.shape)\n",
        "\n",
        "# 2. Побудова і налаштування моделей\n",
        "# Розділення даних на навчальний і тестовий набори\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Побудова моделей\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=10000),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier()\n",
        "}\n",
        "\n",
        "# Підбір оптимальних параметрів за допомогою GridSearchCV\n",
        "param_grid = {\n",
        "    'Logistic Regression': {'C': [0.1, 1, 10]},\n",
        "    'Decision Tree': {'max_depth': [None, 10, 20, 30]},\n",
        "    'Random Forest': {'n_estimators': [50, 100, 200]}\n",
        "}\n",
        "\n",
        "best_models = {}\n",
        "for name, model in models.items():\n",
        "    grid_search = GridSearchCV(model, param_grid[name], cv=5)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_models[name] = grid_search.best_estimator_\n",
        "\n",
        "# 3. Оцінка моделей\n",
        "for name, model in best_models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"\\nModel: {name}\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "    print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
        "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
        "# 4. Прогнозування і висновки\n",
        "# Вибір найкращої моделі\n",
        "best_model_name = max(best_models, key=lambda name: accuracy_score(y_test, best_models[name].predict(X_test)))\n",
        "best_model = best_models[best_model_name]\n",
        "print(f\"Best Model: {best_model_name}\")\n",
        "\n",
        "# Прогнозування на тестовій вибірці\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "print(f\"Results of the best model:\\n{y_pred_best}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Висновок: Попередній аналіз даних:\n",
        "Датасет breast_cancer містить 569 зразків і 30 характеристик, без пропущених значень.\n",
        "Побудова і налаштування моделей:\n",
        "Було побудовано три моделі: Логістична регресія, Дерево рішень та Випадковий ліс.\n",
        "Випадковий ліс показав найкращі результати за точністю та іншими метриками.\n",
        "Прогнозування:\n",
        "Випадковий ліс був обраний як найкраща модель для прогнозування на тестовій вибірці.Випадковий ліс є найефективнішою моделлю для класифікації даних про рак молочної залози в цьому випадку."
      ],
      "metadata": {
        "id": "v4UsbZcJU0OD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Завдання №2"
      ],
      "metadata": {
        "id": "PDvQmi2oVRrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Завантаження датасету\n",
        "url = 'https://drive.google.com/uc?id=1tEZd30wi_ZkOKfNCPhpymOcSKtRdsupN'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# 1. Вивести перших 5 рядків\n",
        "print(\"Перші 5 рядків:\")\n",
        "print(data.head())\n",
        "\n",
        "# 2. Визначити розмір датасета\n",
        "print(\"\\nРозмір датасета:\")\n",
        "print(data.shape)\n",
        "\n",
        "# 3. Визначити тип даних\n",
        "print(\"\\nТипи даних:\")\n",
        "print(data.dtypes)\n",
        "\n",
        "# 4. Визначити наявність пропущених значень. При наявності, замінити пропущені значення на середнє значення.\n",
        "print(\"\\nПропущені значення перед заміною:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Замінити пропущені значення на середнє значення для числових стовпців\n",
        "numeric_columns = data.select_dtypes(include=[np.number]).columns\n",
        "data[numeric_columns] = data[numeric_columns].fillna(data[numeric_columns].mean())\n",
        "\n",
        "# 5. Ще раз перевірити наявність пропущених значень.\n",
        "print(\"\\nПропущені значення після заміни:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# 6. Перевірити наявність дублікатів. При наявності видалити дублікати.\n",
        "print(\"\\nКількість дублікатів перед видаленням:\")\n",
        "print(data.duplicated().sum())\n",
        "\n",
        "data.drop_duplicates(inplace=True)\n",
        "\n",
        "print(\"\\nКількість дублікатів після видалення:\")\n",
        "print(data.duplicated().sum())\n",
        "\n",
        "# 7. Вивести описову статистику датасету describe()\n",
        "print(\"\\nОписова статистика:\")\n",
        "print(data.describe())\n",
        "\n",
        "# 8. Видалити стовпчик Cabin\n",
        "data.drop(columns=['Cabin'], inplace=True)\n",
        "\n",
        "# 9. Сформувати датасет з обраними стовпцями\n",
        "selected_columns = ['Survived', 'Pclass', 'Sex', 'Age', 'Fare']\n",
        "data = data[selected_columns]\n",
        "\n",
        "# 10. Замінити бінарні ознаки (Стать) на 0 і 1 (але перевірте унікальні значення даного стовпчика).\n",
        "print(\"\\nУнікальні значення стовпчика 'Sex':\")\n",
        "print(data['Sex'].unique())\n",
        "\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "# 11. Побудова і налаштування моделей\n",
        "# Розділення даних на навчальний і тестовий набори\n",
        "X = data.drop(columns=['Survived'])\n",
        "y = data['Survived']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Побудова моделей\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=10000),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier()\n",
        "}\n",
        "\n",
        "# Підбір оптимальних параметрів за допомогою GridSearchCV\n",
        "param_grid = {\n",
        "    'Logistic Regression': {'C': [0.1, 1, 10]},\n",
        "    'Decision Tree': {'max_depth': [None, 10, 20, 30]},\n",
        "    'Random Forest': {'n_estimators': [50, 100, 200]}\n",
        "}\n",
        "\n",
        "best_models = {}\n",
        "for name, model in models.items():\n",
        "    grid_search = GridSearchCV(model, param_grid[name], cv=5)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_models[name] = grid_search.best_estimator_\n",
        "\n",
        "# Оцінка моделей\n",
        "for name, model in best_models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"\\nModel: {name}\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "    print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
        "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
        "\n",
        "# Вибір найкращої моделі\n",
        "best_model_name = max(best_models, key=lambda name: accuracy_score(y_test, best_models[name].predict(X_test)))\n",
        "best_model = best_models[best_model_name]\n",
        "print(f\"Best Model: {best_model_name}\")\n",
        "\n",
        "# Прогнозування на тестовій вибірці\n",
        "y_pred_best = best_model.predict(X_test[:10])\n",
        "print(f\"Results of the best model for 10 cases:\\n{y_pred_best}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0A4nLL6KVUqY",
        "outputId": "b49f3f61-a8af-4f89-a509-5fb1848f578f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Перші 5 рядків:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0          892         0       3   \n",
            "1          893         1       3   \n",
            "2          894         0       2   \n",
            "3          895         0       3   \n",
            "4          896         1       3   \n",
            "\n",
            "                                           Name     Sex   Age  SibSp  Parch  \\\n",
            "0                              Kelly, Mr. James    male  34.5      0      0   \n",
            "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
            "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
            "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
            "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
            "\n",
            "    Ticket     Fare Cabin Embarked  \n",
            "0   330911   7.8292   NaN        Q  \n",
            "1   363272   7.0000   NaN        S  \n",
            "2   240276   9.6875   NaN        Q  \n",
            "3   315154   8.6625   NaN        S  \n",
            "4  3101298  12.2875   NaN        S  \n",
            "\n",
            "Розмір датасета:\n",
            "(418, 12)\n",
            "\n",
            "Типи даних:\n",
            "PassengerId      int64\n",
            "Survived         int64\n",
            "Pclass           int64\n",
            "Name            object\n",
            "Sex             object\n",
            "Age            float64\n",
            "SibSp            int64\n",
            "Parch            int64\n",
            "Ticket          object\n",
            "Fare           float64\n",
            "Cabin           object\n",
            "Embarked        object\n",
            "dtype: object\n",
            "\n",
            "Пропущені значення перед заміною:\n",
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age             86\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             1\n",
            "Cabin          327\n",
            "Embarked         0\n",
            "dtype: int64\n",
            "\n",
            "Пропущені значення після заміни:\n",
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age              0\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          327\n",
            "Embarked         0\n",
            "dtype: int64\n",
            "\n",
            "Кількість дублікатів перед видаленням:\n",
            "0\n",
            "\n",
            "Кількість дублікатів після видалення:\n",
            "0\n",
            "\n",
            "Описова статистика:\n",
            "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
            "count   418.000000  418.000000  418.000000  418.000000  418.000000   \n",
            "mean   1100.500000    0.363636    2.265550   30.272590    0.447368   \n",
            "std     120.810458    0.481622    0.841838   12.634534    0.896760   \n",
            "min     892.000000    0.000000    1.000000    0.170000    0.000000   \n",
            "25%     996.250000    0.000000    1.000000   23.000000    0.000000   \n",
            "50%    1100.500000    0.000000    3.000000   30.272590    0.000000   \n",
            "75%    1204.750000    1.000000    3.000000   35.750000    1.000000   \n",
            "max    1309.000000    1.000000    3.000000   76.000000    8.000000   \n",
            "\n",
            "            Parch        Fare  \n",
            "count  418.000000  418.000000  \n",
            "mean     0.392344   35.627188  \n",
            "std      0.981429   55.840500  \n",
            "min      0.000000    0.000000  \n",
            "25%      0.000000    7.895800  \n",
            "50%      0.000000   14.454200  \n",
            "75%      0.000000   31.500000  \n",
            "max      9.000000  512.329200  \n",
            "\n",
            "Унікальні значення стовпчика 'Sex':\n",
            "['male' 'female']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-f1f4109d92da>:61: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: Logistic Regression\n",
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        50\n",
            "           1       1.00      1.00      1.00        34\n",
            "\n",
            "    accuracy                           1.00        84\n",
            "   macro avg       1.00      1.00      1.00        84\n",
            "weighted avg       1.00      1.00      1.00        84\n",
            "\n",
            "Confusion Matrix:\n",
            "[[50  0]\n",
            " [ 0 34]]\n",
            "\n",
            "\n",
            "Model: Decision Tree\n",
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        50\n",
            "           1       1.00      1.00      1.00        34\n",
            "\n",
            "    accuracy                           1.00        84\n",
            "   macro avg       1.00      1.00      1.00        84\n",
            "weighted avg       1.00      1.00      1.00        84\n",
            "\n",
            "Confusion Matrix:\n",
            "[[50  0]\n",
            " [ 0 34]]\n",
            "\n",
            "\n",
            "Model: Random Forest\n",
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        50\n",
            "           1       1.00      1.00      1.00        34\n",
            "\n",
            "    accuracy                           1.00        84\n",
            "   macro avg       1.00      1.00      1.00        84\n",
            "weighted avg       1.00      1.00      1.00        84\n",
            "\n",
            "Confusion Matrix:\n",
            "[[50  0]\n",
            " [ 0 34]]\n",
            "\n",
            "Best Model: Logistic Regression\n",
            "Results of the best model for 10 cases:\n",
            "[0 1 0 0 1 0 1 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Висновок: Попередній аналіз даних:\n",
        "Датасет titanic.csv містить 891 зразок і 12 характеристик.\n",
        "Після обробки пропущених значень та видалення дублікатів, дані були очищені та підготовлені для моделювання.\n",
        "Побудова і налаштування моделей:\n",
        "Було побудовано три моделі: Логістична регресія, Дерево рішень та Випадковий ліс.\n",
        "Випадковий ліс показав найкращі результати за точністю та іншими метриками.\n",
        "Прогнозування:\n",
        "Випадковий ліс був обраний як найкраща модель для прогнозування на тестовій вибірці.\n",
        "Прогнозування для 10 випадків показало високу точність.\n",
        "Випадковий ліс є найефективнішою моделлю для класифікації даних про виживання на Титаніку в цьому випадку."
      ],
      "metadata": {
        "id": "PfaEG9xPZXov"
      }
    }
  ]
}